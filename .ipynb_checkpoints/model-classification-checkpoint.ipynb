{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# filter warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "# keras imports\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.models import model_from_json\n",
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import h5py\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] start time - 2018-10-28 05:53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:37: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"cu...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] successfully loaded base model and model...\n",
      "[INFO] encoding labels...\n",
      "[INFO] completed label - dent\n",
      "[INFO] completed label - scratch\n",
      "[INFO] completed label - undamaged\n"
     ]
    }
   ],
   "source": [
    "# load the user configs\n",
    "with open('/conf/conf.json') as f:    \n",
    "  config = json.load(f)\n",
    "\n",
    "# config variables\n",
    "model_name    = config[\"model\"]\n",
    "weights     = config[\"weights\"]\n",
    "include_top   = config[\"include_top\"]\n",
    "train_path    = config[\"train_path\"]\n",
    "features_path   = config[\"features_path\"]\n",
    "labels_path   = config[\"labels_path\"]\n",
    "test_size     = config[\"test_size\"]\n",
    "results     = config[\"results\"]\n",
    "model_path    = config[\"model_path\"]\n",
    "\n",
    "# start time\n",
    "print (\"[STATUS] start time - {}\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")))\n",
    "start = time.time()\n",
    "\n",
    "# create the pretrained models\n",
    "# check for pretrained weight usage or not\n",
    "# check for top layers to be included or not\n",
    "base_model = InceptionV3(include_top=include_top, weights=weights, input_tensor=Input(shape=(299,299,3)))\n",
    "model = Model(input=base_model.input, output=base_model.get_layer('custom').output)\n",
    "image_size = (299, 299)\n",
    "\n",
    "print (\"[INFO] successfully loaded base model and model...\")\n",
    "\n",
    "# path to training dataset\n",
    "train_labels = os.listdir(train_path)\n",
    "\n",
    "# encode the labels\n",
    "print (\"[INFO] encoding labels...\")\n",
    "le = LabelEncoder()\n",
    "le.fit([tl for tl in train_labels])\n",
    "\n",
    "# variables to hold features and labels\n",
    "features = []\n",
    "labels   = []\n",
    "\n",
    "# loop over all the labels in the folder\n",
    "count = 1\n",
    "for i, label in enumerate(train_labels):\n",
    "  cur_path = train_path + \"/\" + label\n",
    "  count = 1\n",
    "  for image_path in glob.glob(cur_path + \"/*.jpg\"):\n",
    "    img = image.load_img(image_path, target_size=image_size)\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    feature = model.predict(x)\n",
    "    flat = feature.flatten()\n",
    "    features.append(flat)\n",
    "    labels.append(label)\n",
    "    #print (\"[INFO] processed - \" + str(count))\n",
    "    count += 1\n",
    "  print (\"[INFO] completed label - \" + label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] training labels shape: (1104,)\n",
      "[STATUS] saved model and weights to disk..\n",
      "[STATUS] features and labels saved..\n",
      "[STATUS] end time - 2018-10-28 06:08\n"
     ]
    }
   ],
   "source": [
    "# encode the labels using LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le_labels = le.fit_transform(labels)\n",
    "\n",
    "# get the shape of training labels\n",
    "#print (\"[STATUS] training labels: {}\".format(le_labels))\n",
    "print (\"[STATUS] training labels shape: {}\".format(le_labels.shape))\n",
    "\n",
    "# save features and labels\n",
    "h5f_data = h5py.File(features_path, 'w')\n",
    "h5f_data.create_dataset('dataset_1', data=np.array(features))\n",
    "\n",
    "h5f_label = h5py.File(labels_path, 'w')\n",
    "h5f_label.create_dataset('dataset_1', data=np.array(le_labels))\n",
    "\n",
    "h5f_data.close()\n",
    "h5f_label.close()\n",
    "\n",
    "# save model and weights\n",
    "model_json = model.to_json()\n",
    "with open(model_path + str(test_size) + \".json\", \"w\") as json_file:\n",
    "  json_file.write(model_json)\n",
    "\n",
    "# save weights\n",
    "model.save_weights(model_path + str(test_size) + \".h5\")\n",
    "print(\"[STATUS] saved model and weights to disk..\")\n",
    "\n",
    "print (\"[STATUS] features and labels saved..\")\n",
    "\n",
    "# end time\n",
    "end = time.time()\n",
    "print (\"[STATUS] end time - {}\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize imports\n",
    "from __future__ import print_function\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the user configs\n",
    "with open('/conf/conf.json') as f:    \n",
    "  config = json.load(f)\n",
    "\n",
    "# config variables\n",
    "test_size     = config[\"test_size\"]\n",
    "seed      = config[\"seed\"]\n",
    "features_path   = config[\"features_path\"]\n",
    "labels_path   = config[\"labels_path\"]\n",
    "results     = config[\"results\"]\n",
    "classifier_path = config[\"classifier_path\"]\n",
    "train_path    = config[\"train_path\"]\n",
    "num_classes   = config[\"num_classes\"]\n",
    "classifier_path = config[\"classifier_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] features shape: (1104, 131072)\n",
      "[INFO] labels shape: (1104,)\n",
      "[INFO] training started...\n",
      "[INFO] splitted train and test data...\n",
      "[INFO] train data  : (993, 131072)\n",
      "[INFO] val data   : (111, 131072)\n",
      "[INFO] train labels: (993,)\n",
      "[INFO] val labels : (111,)\n"
     ]
    }
   ],
   "source": [
    "# import features and labels\n",
    "h5f_data  = h5py.File(features_path, 'r')\n",
    "h5f_label = h5py.File(labels_path, 'r')\n",
    "\n",
    "features_string = h5f_data['dataset_1']\n",
    "labels_string   = h5f_label['dataset_1']\n",
    "\n",
    "features = np.array(features_string)\n",
    "labels   = np.array(labels_string)\n",
    "\n",
    "h5f_data.close()\n",
    "h5f_label.close()\n",
    "\n",
    "# verify the shape of features and labels\n",
    "print (\"[INFO] features shape: {}\".format(features.shape))\n",
    "print (\"[INFO] labels shape: {}\".format(labels.shape))\n",
    "\n",
    "print (\"[INFO] training started...\")\n",
    "# split the training and validation data\n",
    "(trainData, valData, trainLabels, valLabels) = train_test_split(np.array(features),\n",
    "                                                                  np.array(labels),\n",
    "                                                                  test_size=test_size,\n",
    "                                                                  random_state=seed)\n",
    "\n",
    "print (\"[INFO] splitted train and test data...\")\n",
    "print (\"[INFO] train data  : {}\".format(trainData.shape))\n",
    "print (\"[INFO] val data   : {}\".format(valData.shape))\n",
    "print (\"[INFO] train labels: {}\".format(trainLabels.shape))\n",
    "print (\"[INFO] val labels : {}\".format(valLabels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating model...\n"
     ]
    }
   ],
   "source": [
    "# use SVM as the model\n",
    "print (\"[INFO] creating model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC(probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(trainData, trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating model...\n"
     ]
    }
   ],
   "source": [
    "# use rank-1 and rank-3 predictions\n",
    "print (\"[INFO] evaluating model...\")\n",
    "f = open(results, \"w\")\n",
    "rank_1 = 0\n",
    "rank_3 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saving model...\n",
      "[INFO] confusion matrix\n"
     ]
    }
   ],
   "source": [
    "# loop over test data\n",
    "for (label, features) in zip(valLabels, valData):\n",
    "  # predict the probability of each class label and\n",
    "  # take the top-5 class labels\n",
    "  predictions = classifier.predict_proba(np.atleast_2d(features))[0]\n",
    "  predictions = np.argsort(predictions)[::-1][:5]\n",
    "\n",
    "  # rank-1 prediction increment\n",
    "  if label == predictions[0]:\n",
    "    rank_1 += 1\n",
    "\n",
    "  # rank-3 prediction increment\n",
    "  if label in predictions[:3]:\n",
    "    rank_3 += 1\n",
    "\n",
    "# convert accuracies to percentages\n",
    "rank_1 = (rank_1 / float(len(valLabels))) * 100\n",
    "rank_3 = (rank_3 / float(len(valLabels))) * 100\n",
    "\n",
    "# write the accuracies to file\n",
    "f.write(\"Rank-1: {:.2f}%\\n\".format(rank_1))\n",
    "f.write(\"Rank-3: {:.2f}%\\n\\n\".format(rank_3))\n",
    "\n",
    "\n",
    "# evaluate the model of train data\n",
    "preds_train = classifier.predict(trainData)\n",
    "\n",
    "# evaluate the model of test data\n",
    "preds_val = classifier.predict(valData)\n",
    "\n",
    "# write the classification report to file\n",
    "f.write(\"{}\\n\".format(classification_report(valLabels, preds_val)))\n",
    "f.close()\n",
    "\n",
    "# dump classifier to file\n",
    "print (\"[INFO] saving model...\")\n",
    "pickle.dump(classifier, open(classifier_path, 'wb'))\n",
    "\n",
    "# display the confusion matrix\n",
    "print (\"[INFO] confusion matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the list of training lables\n",
    "labels = sorted(list(os.listdir(train_path)))\n",
    "\n",
    "# plot the confusion matrix\n",
    "cm = confusion_matrix(valLabels, preds_val)\n",
    "sns.heatmap(cm,\n",
    "            annot=True,\n",
    "            cmap=\"Set2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = accuracy_score(trainLabels, preds_train)\n",
    "with open('train.txt', 'w') as f:\n",
    "    f.write(\"The training accuracy is:\" + str(train_accuracy) + '\\n\\n')\n",
    "#     f.write(\"The actual labels are:\" + str([train_labels[idx] for idx in trainLabels]) + '\\n\\n')\n",
    "#     f.write(\"The predicted labels are:\" + str([train_labels[idx] for idx in preds_train]) + '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracy = accuracy_score(valLabels, preds_val)\n",
    "with open('val.txt', 'w') as f:\n",
    "    f.write(\"The validation accuracy is:\" + str(val_accuracy) + '\\n\\n')\n",
    "#     f.write(\"The actual labels are:\" + str([train_labels[idx] for idx in valLabels]) + '\\n\\n')\n",
    "#     f.write(\"The predicted labels are:\" + str([train_labels[idx] for idx in preds_val]) + '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
